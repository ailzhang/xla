diff --git a/torch/_utils.py b/torch/_utils.py
index 657102ed1..a246f23aa 100644
--- a/torch/_utils.py
+++ b/torch/_utils.py
@@ -140,6 +140,12 @@ def _rebuild_tensor_v2(storage, storage_offset, size, stride, requires_grad, bac
     tensor._backward_hooks = backward_hooks
     return tensor
 
+def _rebuild_xlatensor(storage, storage_offset, size, stride, requires_grad, backward_hooks, device):
+    tensor = _rebuild_tensor(storage, storage_offset, size, stride).to(device)
+    tensor.requires_grad = requires_grad
+    tensor._backward_hooks = backward_hooks
+    return tensor
+
 def _rebuild_qtensor(storage, storage_offset, size, stride, scale, zero_point, requires_grad, backward_hooks):
     tensor = torch._empty_affine_quantized(size, scale=scale, zero_point=zero_point, dtype=storage.dtype)
     tensor.set_(storage, storage_offset, size, stride)
diff --git a/torch/serialization.py b/torch/serialization.py
index 8b168b694..4213d4b0a 100644
--- a/torch/serialization.py
+++ b/torch/serialization.py
@@ -312,6 +312,8 @@ def _save(obj, f, pickle_module, pickle_protocol):
                     location,
                     obj.size(),
                     view_metadata)
+        elif isinstance(obj, torch.device) and obj.type == 'xla':
+               return ('OpaqueDevice', 'cpu')
         return None
 
     sys_info = dict(
@@ -578,6 +580,9 @@ def _load(f, map_location, pickle_module, **pickle_load_args):
                 return deserialized_objects[view_key]
             else:
                 return storage
+        elif typename == 'OpaqueDevice':
+            device_name = data[0]
+            return torch.device(device_name)
         else:
             raise RuntimeError("Unknown saved id type: %s" % saved_id[0])
 
diff --git a/torch/tensor.py b/torch/tensor.py
index a7724a4a3..7e31988ec 100644
--- a/torch/tensor.py
+++ b/torch/tensor.py
@@ -40,6 +40,16 @@ class Tensor(torch._C._TensorBase):
         _check_serializing_named_tensor(self)
         # See Note [Don't serialize hooks]
         torch.utils.hooks.warn_if_has_hooks(self)
+        if self.device.type == 'xla':
+            self_cpu = self.cpu()
+            args = (self_cpu.storage(),
+                    self_cpu.storage_offset(),
+                    tuple(self.size()),
+                    self_cpu.stride(),
+                    self.requires_grad,
+                    OrderedDict(),
+                    self.device)
+            return (torch._utils._rebuild_xlatensor, args)
         if self.is_quantized:
             args = (self.storage(),
                     self.storage_offset(),
