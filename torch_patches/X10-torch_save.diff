diff --git a/torch/_utils.py b/torch/_utils.py
index ba5ef2544..4e567a0a5 100644
--- a/torch/_utils.py
+++ b/torch/_utils.py
@@ -130,6 +130,11 @@ def _rebuild_tensor(storage, storage_offset, size, stride):
     t = torch.tensor([], dtype=storage.dtype, device=storage.device)
     return t.set_(storage, storage_offset, size, stride)
 
+def _rebuild_xlatensor(storage, storage_offset, size, stride, requires_grad, backward_hooks, device):
+    tensor = _rebuild_tensor(storage, storage_offset, size, stride).to(device)
+    tensor.requires_grad = requires_grad
+    tensor._backward_hooks = backward_hooks
+    return tensor
 
 def _rebuild_tensor_v2(storage, storage_offset, size, stride, requires_grad, backward_hooks):
     tensor = _rebuild_tensor(storage, storage_offset, size, stride)
diff --git a/torch/serialization.py b/torch/serialization.py
index a3e0bc9b0..2f5db1ec3 100644
--- a/torch/serialization.py
+++ b/torch/serialization.py
@@ -312,6 +312,8 @@ def _save(obj, f, pickle_module, pickle_protocol):
                     location,
                     obj.size(),
                     view_metadata)
+        elif isinstance(obj, torch.device) and obj.type == 'xla':
+               return ('OpaqueDevice', 'cpu')
         return None
 
     sys_info = dict(
@@ -578,6 +580,9 @@ def _load(f, map_location, pickle_module, **pickle_load_args):
                 return deserialized_objects[view_key]
             else:
                 return storage
+        elif typename == 'OpaqueDevice':
+            device_name = data[0]
+            return torch.device(device_name)
         else:
             raise RuntimeError("Unknown saved id type: %s" % saved_id[0])
 
diff --git a/torch/tensor.py b/torch/tensor.py
index e74103e4f..701f613c9 100644
--- a/torch/tensor.py
+++ b/torch/tensor.py
@@ -41,6 +41,16 @@ class Tensor(torch._C._TensorBase):
         check_serializing_named_tensor(self)
         # See Note [Don't serialize hooks]
         torch.utils.hooks.warn_if_has_hooks(self)
+        if self.device.type == 'xla':
+            self_cpu = self.cpu()
+            args = (self_cpu.storage(),
+                    self_cpu.storage_offset(),
+                    tuple(self.size()),
+                    self_cpu.stride(),
+                    self.requires_grad,
+                    OrderedDict(),
+                    self.device)
+            return (torch._utils._rebuild_xlatensor, args)
         if self.is_quantized:
             if self.qscheme() == torch.per_tensor_affine:
                 quantizer_params = (torch.per_tensor_affine,
